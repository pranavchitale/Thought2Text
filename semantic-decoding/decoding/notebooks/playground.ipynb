{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import config\n",
    "from GPT import GPT\n",
    "from StimulusModel import LMFeatures\n",
    "from utils_stim import get_stim\n",
    "from utils_resp import get_resp\n",
    "from utils_ridge.ridge import ridge, bootstrap_ridge\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get path errors, then change dir using os.chdir to 'whatever-your-root-is/semantic-decoding/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--subject\", type = str, required = True)\n",
    "parser.add_argument(\"--gpt\", type = str, default = \"perceived\")\n",
    "parser.add_argument(\"--sessions\", nargs = \"+\", type = int, default = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 20])\n",
    "args = parser.parse_args(\"--subject S1\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training stories\n",
    "stories = []\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"sess_to_story.json\"), \"r\") as f:\n",
    "    sess_to_story = json.load(f) \n",
    "for sess in args.sessions:\n",
    "    stories.extend(sess_to_story[str(sess)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# load gpt\n",
    "with open(os.path.join(config.DATA_LM_DIR, args.gpt, \"vocab.json\"), \"r\") as f:\n",
    "    gpt_vocab = json.load(f)\n",
    "gpt = GPT(path = os.path.join(config.DATA_LM_DIR, args.gpt, \"model\"), vocab = gpt_vocab, device = config.GPT_DEVICE)\n",
    "features = LMFeatures(model = gpt, layer = config.GPT_LAYER, context_words = config.GPT_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate encoding model\n",
    "rstim, tr_stats, word_stats = get_stim(stories, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rresp = get_resp(args.subject, stories, stack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27449, 81126)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rresp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchunks = int(np.ceil(rresp.shape[0] / 5 / config.CHUNKLEN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, alphas, bscorrs = bootstrap_ridge(rstim, rresp, use_corr = False, alphas = config.ALPHAS, nboots = config.NBOOTS, chunklen = config.CHUNKLEN, nchunks = nchunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 81126)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/workspace/weights/S1.npy', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscorrs = bscorrs.mean(2).max(0)\n",
    "vox = np.sort(np.argsort(bscorrs)[-config.VOXELS:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_dict = {story : get_stim([story], features, tr_stats = tr_stats) for story in stories}\n",
    "resp_dict = get_resp(args.subject, stories, stack = False, vox = vox)\n",
    "noise_model = np.zeros([len(vox), len(vox)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 138min 16.9s\n",
    "\n",
    "for hstory in stories:\n",
    "    tstim, hstim = np.vstack([stim_dict[tstory] for tstory in stories if tstory != hstory]), stim_dict[hstory]\n",
    "    tresp, hresp = np.vstack([resp_dict[tstory] for tstory in stories if tstory != hstory]), resp_dict[hstory]\n",
    "    bs_weights = ridge(tstim, tresp, alphas[vox])\n",
    "    resids = hresp - hstim.dot(bs_weights)\n",
    "    bs_noise_model = resids.T.dot(resids)\n",
    "    noise_model += bs_noise_model / np.diag(bs_noise_model).mean() / len(stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "save_location = os.path.join(config.MODEL_DIR, args.subject)\n",
    "os.makedirs(save_location, exist_ok = True)\n",
    "np.savez(os.path.join(save_location, \"encoding_model_%s\" % args.gpt), \n",
    "    weights = weights, noise_model = noise_model, alphas = alphas, voxels = vox, stories = stories,\n",
    "    tr_stats = np.array(tr_stats), word_stats = np.array(word_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Wordrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import config\n",
    "from utils_stim import get_story_wordseqs\n",
    "from utils_resp import get_resp\n",
    "from utils_ridge.DataSequence import DataSequence\n",
    "from utils_ridge.util import make_delayed\n",
    "from utils_ridge.ridge import bootstrap_ridge\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--subject\", type = str, required = True)\n",
    "parser.add_argument(\"--sessions\", nargs = \"+\", type = int, \n",
    "    default = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 20])\n",
    "args = parser.parse_args(\"--subject S1\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training stories\n",
    "stories = []\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"sess_to_story.json\"), \"r\") as f:\n",
    "    sess_to_story = json.load(f) \n",
    "for sess in args.sessions:\n",
    "    stories.extend(sess_to_story[str(sess)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI voxels\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"ROIs\", \"%s.json\" % args.subject), \"r\") as f:\n",
    "    vox = json.load(f)\n",
    "        \n",
    "# estimate word rate model\n",
    "save_location = os.path.join(config.MODEL_DIR, args.subject)\n",
    "os.makedirs(save_location, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordseqs = get_story_wordseqs(stories)\n",
    "rates = {}\n",
    "for story in stories:\n",
    "    ds = wordseqs[story]\n",
    "    words = DataSequence(np.ones(len(ds.data_times)), ds.split_inds, ds.data_times, ds.tr_times)\n",
    "    rates[story] = words.chunksums(\"lanczos\", window = 3)\n",
    "nz_rate = np.concatenate([rates[story][5+config.TRIM:-config.TRIM] for story in stories], axis = 0)\n",
    "nz_rate = np.nan_to_num(nz_rate).reshape([-1, 1])\n",
    "mean_rate = np.mean(nz_rate)\n",
    "rate = nz_rate - mean_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 35m 25.9s\n",
    "\n",
    "for roi in [\"speech\", \"auditory\"]:\n",
    "    resp = get_resp(args.subject, stories, stack = True, vox = vox[roi])\n",
    "    delresp = make_delayed(resp, config.RESP_DELAYS)\n",
    "    nchunks = int(np.ceil(delresp.shape[0] / 5 / config.CHUNKLEN))    \n",
    "    weights, _, _ = bootstrap_ridge(delresp, rate, use_corr = False,\n",
    "        alphas = config.ALPHAS, nboots = config.NBOOTS, chunklen = config.CHUNKLEN, nchunks = nchunks)\n",
    "    np.savez(os.path.join(save_location, \"word_rate_model_%s\" % roi), \n",
    "        weights = weights, mean_rate = mean_rate, voxels = vox[roi])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/chronos_data/rrao/conda/envs/thought2text/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/chronos_data/rrao/conda/envs/thought2text/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/chronos_data/rrao/conda/envs/thought2text/lib/python3.10/site-packages/torch/__init__.py:747: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /opt/conda/conda-bld/pytorch_1712608839953/work/torch/csrc/tensor/python_tensor.cpp:431.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "import config\n",
    "from GPT import GPT\n",
    "from Decoder import Decoder, Hypothesis\n",
    "from LanguageModel import LanguageModel\n",
    "from EncodingModel import EncodingModel\n",
    "from StimulusModel import StimulusModel, get_lanczos_mat, affected_trs, LMFeatures\n",
    "from utils_stim import predict_word_rate, predict_word_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--subject\", type = str, default = \"S1\")\n",
    "parser.add_argument(\"--experiment\", type = str, default = \"perceived_speech\")\n",
    "parser.add_argument(\"--task\", type = str, default = \"wheretheressmoke\")\n",
    "parser.add_argument(\"--variant\", type = str, default = \"base\", choices = [\"base\", \"mlp\", \"gpt2\"])\n",
    "parser.add_argument(\"--mlp_path\", type = str, default = \"\", help = \"Specify path to checkpoint file if `mlp` variant is selected\")\n",
    "args = parser.parse_args(\"--subject S1 --experiment perceived_speech --task wheretheressmoke\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine GPT checkpoint based on experiment\n",
    "if args.experiment in [\"imagined_speech\"]: gpt_checkpoint = \"imagined\"\n",
    "else: gpt_checkpoint = \"perceived\"\n",
    "\n",
    "# determine word rate model voxels based on experiment\n",
    "if args.experiment in [\"imagined_speech\", \"perceived_movies\"]: word_rate_voxels = \"speech\"\n",
    "else: word_rate_voxels = \"auditory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File(os.path.join(config.DATA_TEST_DIR, \"test_response\", args.subject, args.experiment, args.task + \".hf5\"), \"r\")\n",
    "resp = np.nan_to_num(hf[\"data\"][:])\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 81126)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt\n",
    "with open(os.path.join(config.DATA_LM_DIR, gpt_checkpoint, \"vocab.json\"), \"r\") as f:\n",
    "    gpt_vocab = json.load(f)\n",
    "with open(os.path.join(config.DATA_LM_DIR, \"decoder_vocab.json\"), \"r\") as f:\n",
    "    decoder_vocab = json.load(f)\n",
    "gpt = GPT(path = os.path.join(config.DATA_LM_DIR, gpt_checkpoint, \"model\"), vocab = gpt_vocab, device = config.GPT_DEVICE)\n",
    "features = LMFeatures(model = gpt, layer = config.GPT_LAYER, context_words = config.GPT_WORDS)\n",
    "lm = LanguageModel(gpt, decoder_vocab, nuc_mass = config.LM_MASS, nuc_ratio = config.LM_RATIO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models\n",
    "load_location = os.path.join(config.MODEL_DIR, args.subject)\n",
    "word_rate_model = np.load(os.path.join(load_location, \"word_rate_model_%s.npz\" % word_rate_voxels), allow_pickle = True)\n",
    "encoding_model = np.load(os.path.join(load_location, \"encoding_model_%s.npz\" % gpt_checkpoint))\n",
    "weights = encoding_model[\"weights\"]\n",
    "noise_model = encoding_model[\"noise_model\"]\n",
    "tr_stats = encoding_model[\"tr_stats\"]\n",
    "word_stats = encoding_model[\"word_stats\"]\n",
    "if args.variant == \"base\":\n",
    "    em = EncodingModel(resp, weights, encoding_model[\"voxels\"], noise_model, device = config.EM_DEVICE)\n",
    "elif args.variant == \"mlp\":\n",
    "    em = EncodingModel(resp, weights, encoding_model[\"voxels\"], noise_model, mlp_path = args.mlp_path, device = config.EM_DEVICE)\n",
    "em.set_shrinkage(config.NM_ALPHA)\n",
    "assert args.task not in encoding_model[\"stories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1186\n",
      "81012\n"
     ]
    }
   ],
   "source": [
    "print(np.min(encoding_model[\"voxels\"]))\n",
    "print(np.max(encoding_model[\"voxels\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/chronos_data/rrao/Thought2Text/semantic-decoding/decoding/utils_ridge/interpdata.py:159: RuntimeWarning: invalid value encountered in divide\n",
      "  val = window * np.sin(np.pi*t) * np.sin(np.pi*t/window) / (np.pi**2 * t**2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict word times\n",
    "word_rate = predict_word_rate(resp, word_rate_model[\"weights\"], word_rate_model[\"voxels\"], word_rate_model[\"mean_rate\"])\n",
    "if args.experiment == \"perceived_speech\": word_times, tr_times = predict_word_times(word_rate, resp, starttime = -10)\n",
    "else: word_times, tr_times = predict_word_times(word_rate, resp, starttime = 0)\n",
    "lanczos_mat = get_lanczos_mat(word_times, tr_times)\n",
    "len(word_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6, 10000])\n",
      "torch.Size([6, 10000])\n",
      "likelihoods.shape:  (6,)\n"
     ]
    }
   ],
   "source": [
    "# 169m 45.9s\n",
    "\n",
    "# decode responses\n",
    "decoder = Decoder(word_times, config.WIDTH)\n",
    "sm = StimulusModel(lanczos_mat, tr_stats, word_stats[0], device = config.SM_DEVICE)\n",
    "for sample_index in range(len(word_times)):\n",
    "    trs = affected_trs(decoder.first_difference(), sample_index, lanczos_mat)\n",
    "    ncontext = decoder.time_window(sample_index, config.LM_TIME, floor = 5)\n",
    "    beam_nucs = lm.beam_propose(decoder.beam, ncontext)\n",
    "    for c, (hyp, nextensions) in enumerate(decoder.get_hypotheses()):\n",
    "        nuc, logprobs = beam_nucs[c]\n",
    "        if len(nuc) < 1: continue\n",
    "        extend_words = [hyp.words + [x] for x in nuc]\n",
    "        extend_embs = list(features.extend(extend_words))\n",
    "        stim = sm.make_variants(sample_index, hyp.embs, extend_embs, trs)\n",
    "        likelihoods = em.prs(stim, trs)\n",
    "        print('likelihoods.shape: ', likelihoods.shape)\n",
    "        local_extensions = [Hypothesis(parent = hyp, extension = x) for x in zip(nuc, logprobs, extend_embs)]\n",
    "        decoder.add_extensions(local_extensions, likelihoods, nextensions)\n",
    "    decoder.extend(verbose = False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.experiment in [\"perceived_movie\", \"perceived_multispeaker\"]: decoder.word_times += 10\n",
    "save_location = os.path.join(config.RESULT_DIR, args.subject, args.experiment)\n",
    "os.makedirs(save_location, exist_ok = True)\n",
    "decoder.save(os.path.join(save_location, args.task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import argparse\n",
    "\n",
    "import config\n",
    "from utils_eval import generate_null, load_transcript, windows, segment_data, WER, BLEU, METEOR, BERTSCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--subject\", type = str, required = True)\n",
    "parser.add_argument(\"--experiment\", type = str, required = True)\n",
    "parser.add_argument(\"--task\", type = str, required = True)\n",
    "parser.add_argument(\"--metrics\", nargs = \"+\", type = str, default = [\"WER\", \"BLEU\", \"METEOR\", \"BERT\"])\n",
    "parser.add_argument(\"--references\", nargs = \"+\", type = str, default = [])\n",
    "parser.add_argument(\"--null\", type = int, default = 10)\n",
    "args = parser.parse_args(\"--subject S1 --experiment perceived_speech --task wheretheressmoke\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(args.references) == 0:\n",
    "    args.references.append(args.task)\n",
    "    \n",
    "with open(os.path.join(config.DATA_TEST_DIR, \"eval_segments.json\"), \"r\") as f:\n",
    "    eval_segments = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2m 52.1s\n",
    "\n",
    "# load language similarity metrics\n",
    "metrics = {}\n",
    "if \"WER\" in args.metrics: metrics[\"WER\"] = WER(use_score = True)\n",
    "if \"BLEU\" in args.metrics: metrics[\"BLEU\"] = BLEU(n = 1)\n",
    "if \"METEOR\" in args.metrics: metrics[\"METEOR\"] = METEOR()\n",
    "if \"BERT\" in args.metrics: metrics[\"BERT\"] = BERTSCORE(\n",
    "    idf_sents = np.load(os.path.join(config.DATA_TEST_DIR, \"idf_segments.npy\")), \n",
    "    rescale = False, \n",
    "    score = \"recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prediction transcript\n",
    "pred_path = os.path.join(config.RESULT_DIR, args.subject, args.experiment, args.task + \".npz\")\n",
    "pred_data = np.load(pred_path)\n",
    "pred_words, pred_times = pred_data[\"words\"], pred_data[\"times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8m 8.9sec\n",
    "\n",
    "# generate null sequences\n",
    "if args.experiment in [\"imagined_speech\"]: gpt_checkpoint = \"imagined\"\n",
    "else: gpt_checkpoint = \"perceived\"\n",
    "null_word_list = generate_null(pred_times, gpt_checkpoint, args.null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "After applying the transforms on the reference and hypothesis sentences, their lengths must match. Instead got 49 reference and 56 hypothesis sentences.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m\n\u001b[1;32m     13\u001b[0m     null_window_list \u001b[38;5;241m=\u001b[39m [segment_data(null_words, pred_times, window_cutoffs) \u001b[38;5;28;01mfor\u001b[39;00m null_words \u001b[38;5;129;01min\u001b[39;00m null_word_list]\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m mname, metric \u001b[38;5;129;01min\u001b[39;00m metrics\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m         \u001b[38;5;66;03m# get null score for each window and the entire story\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m         \u001b[38;5;66;03m# get raw score and normalized score for the entire story\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         story_scores[(reference, mname)] \u001b[38;5;241m=\u001b[39m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mref_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpred_windows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# story_zscores[(reference, mname)] = (story_scores[(reference, mname)].mean()\u001b[39;00m\n\u001b[1;32m     30\u001b[0m                                                 \u001b[38;5;66;03m# - story_null_scores.mean()) / story_null_scores.std()\u001b[39;00m\n\u001b[1;32m     32\u001b[0m save_location \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config\u001b[38;5;241m.\u001b[39mREPO_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscores\u001b[39m\u001b[38;5;124m\"\u001b[39m, args\u001b[38;5;241m.\u001b[39msubject, args\u001b[38;5;241m.\u001b[39mexperiment)\n",
      "File \u001b[0;32m/chronos_data/rrao/Thought2Text/semantic-decoding/decoding/utils_eval.py:83\u001b[0m, in \u001b[0;36mWER.score\u001b[0;34m(self, ref, pred)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ref_seg, pred_seg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ref, pred):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ref_seg) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m : error \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: error \u001b[38;5;241m=\u001b[39m \u001b[43mwer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_seg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_seg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_score: scores\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m error)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: use_score\u001b[38;5;241m.\u001b[39mappend(error)\n",
      "File \u001b[0;32m/chronos_data/rrao/conda/envs/thought2text/lib/python3.10/site-packages/jiwer/measures.py:111\u001b[0m, in \u001b[0;36mwer\u001b[0;34m(reference, hypothesis, reference_transform, hypothesis_transform, truth, truth_transform)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03mCalculate the word error rate (WER) between one or more reference and\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03mhypothesis sentences.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m             hypothesis sentence(s).\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m (\n\u001b[1;32m     98\u001b[0m     reference,\n\u001b[1;32m     99\u001b[0m     hypothesis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     hypothesis_transform\u001b[38;5;241m=\u001b[39mhypothesis_transform,\n\u001b[1;32m    109\u001b[0m )\n\u001b[0;32m--> 111\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_words\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypothesis_transform\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\u001b[38;5;241m.\u001b[39mwer\n",
      "File \u001b[0;32m/chronos_data/rrao/conda/envs/thought2text/lib/python3.10/site-packages/jiwer/process.py:170\u001b[0m, in \u001b[0;36mprocess_words\u001b[0;34m(reference, hypothesis, reference_transform, hypothesis_transform)\u001b[0m\n\u001b[1;32m    165\u001b[0m hyp_transformed \u001b[38;5;241m=\u001b[39m _apply_transform(\n\u001b[1;32m    166\u001b[0m     hypothesis, hypothesis_transform, is_reference\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    167\u001b[0m )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ref_transformed) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(hyp_transformed):\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter applying the transforms on the reference and hypothesis sentences, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtheir lengths must match. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ref_transformed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reference and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(hyp_transformed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m hypothesis sentences.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# Change each word into a unique character in order to compute\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# word-level levenshtein distance\u001b[39;00m\n\u001b[1;32m    179\u001b[0m ref_as_chars, hyp_as_chars \u001b[38;5;241m=\u001b[39m _word2char(ref_transformed, hyp_transformed)\n",
      "\u001b[0;31mValueError\u001b[0m: After applying the transforms on the reference and hypothesis sentences, their lengths must match. Instead got 49 reference and 56 hypothesis sentences."
     ]
    }
   ],
   "source": [
    "window_scores, window_zscores = {}, {}\n",
    "story_scores, story_zscores = {}, {}\n",
    "for reference in args.references:\n",
    "\n",
    "    # load reference transcript\n",
    "    ref_data = load_transcript(args.experiment, reference)\n",
    "    ref_words, ref_times = ref_data[\"words\"], ref_data[\"times\"]\n",
    "\n",
    "    # segment prediction and reference words into windows\n",
    "    window_cutoffs = windows(*eval_segments[args.task], config.WINDOW)\n",
    "    ref_windows = segment_data(ref_words, ref_times, window_cutoffs)\n",
    "    pred_windows = segment_data(pred_words, pred_times, window_cutoffs)\n",
    "    null_window_list = [segment_data(null_words, pred_times, window_cutoffs) for null_words in null_word_list]\n",
    "    \n",
    "    for mname, metric in metrics.items():\n",
    "\n",
    "        # get null score for each window and the entire story\n",
    "        window_null_scores = np.array([metric.score(ref = ref_windows, pred = null_windows) \n",
    "                                        for null_windows in null_window_list])\n",
    "        story_null_scores = window_null_scores.mean(1)\n",
    "\n",
    "        # get raw score and normalized score for each window\n",
    "        window_scores[(reference, mname)] = metric.score(ref = ref_windows, pred = pred_windows)\n",
    "        window_zscores[(reference, mname)] = (window_scores[(reference, mname)] \n",
    "                                                - window_null_scores.mean(0)) / window_null_scores.std(0)\n",
    "\n",
    "        # get raw score and normalized score for the entire story\n",
    "        story_scores[(reference, mname)] = metric.score(ref = ref_windows, pred = pred_windows)\n",
    "        story_zscores[(reference, mname)] = (story_scores[(reference, mname)].mean()\n",
    "                                                - story_null_scores.mean()) / story_null_scores.std()\n",
    "\n",
    "save_location = os.path.join(config.REPO_DIR, \"scores\", args.subject, args.experiment)\n",
    "os.makedirs(save_location, exist_ok = True)\n",
    "np.savez(os.path.join(save_location, args.task), \n",
    "            window_scores = window_scores, window_zscores = window_zscores, \n",
    "            story_scores = story_scores, story_zscores = story_zscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "she was doing i don't remember her being drunk but i was sure i saw her leave with my son at this point she is talking about the car accident i remember thinking she must be in pain i thought of her as my best friend but she had been shot i told myself she was dead i got the idea that it wasn't her but i was wrong she had her life but the people around me did not it was a time where she felt alone i am sorry but she needed to make it through it it is her family and not me that are suffering now i think she was in pain and the idea of my being there made her sick i also know that the doctor was there because of me and he is a good guy so i went on to do everything right and i didn't go home but he got to see my work and he liked the results i made the decision to hire someone for his project and i did the work myself the company did it and the guy who ran it was the manager at the time and i think they really liked the music so the other kids are just sitting around watching it i think that if they could do that the whole time i would be playing with them i am sure the idea of having them on the bus is terrifying i had to get one in my house i got it but it wasn't mine my mother said it was hers and the man told me she was using it i knew that he was lying i would be honest about it so i did she had it with her i am pretty sure he is gay too but she wasn't with me i have to tell her that she is wrong i don't know what it was she was in my head but i felt her presence there i had to keep fighting it i would be ok she was in my mind but she wasn't there my friends told me that she died that day so i got her a card but it didn't make me happy she was in my head but not my heart i just kept talking about it to myself i could see myself becoming obsessed with it it was a big thing in the end i told my friends and i started taking pictures of it i would get to it later so i could use it in school but not when the students were talking about it i would tell them i couldn't remember and that the class was already finished and to go home the teacher said that if i was to make any progress it was time to stop my writing i had to do something about it but i was terrified of losing myself and that i would go into depression the other day and be unable to move i had a panic attack about it and started vomiting in the toilet i then told her about my episode and how it made me feel when she left i had a panic attack about minutes later when i saw the video she said i should have died she had to tell me to stay awake i had a vision of her in my room and the dream ended when she said you have to find him she told me he is gone i don't believe it she was in tears i am convinced she is lying my family was there that day i was at home when it happened but my wife was in a meeting and the kids were not in school i got the impression they were doing homework or something as she was gone i then told them to take the bus home they didn't argue but i guess the whole point of driving was to be a good driver but then i got caught i had a ticket the other night for smoking weed so i just asked for it to pass i get it in and go to the bathroom i feel the pain and look around for something to stop the bleeding and my friend sees it and grabs it i was crying because of the blood but the man didn't notice that and i think the woman was going to kill me if he didn't stop she was already walking away he was on her heels when the woman screamed i hate you and grabbed a handful of the guy she then went for the door she was in shock i told her i could get her home but she said i have a job so she would go i had to do this all the time so i ended up doing this with her the first couple months but she didn't do it anymore then we got together the second thing is i never saw him again the whole time he was gone my mom still thinks he died the other day i told her about his funeral i didn't mention his family i had to explain that the guy died on a bus and that i couldn't tell anyone i could find his family because he was dead they don't know i am going to take them in i can feel it they have a problem i was told that the school is closed this morning and the kids in the parking lot have been dismissed and i can see that my son is standing in his spot i think the guy was crying i don't know he was in tears i guess my dad got him in trouble but the teacher told my brother to stop crying i think she had him do it i was at a school dance the whole time and he had gotten into the ring so i could see the competition and was a bit nervous the night before the match but i got up and said that i was ready for this i would see her on tuesday i had no idea how to find her she had never told me her name i knew that she was homeless so i didn't press it she had her own money i think and we were pretty close the day she died it was her funeral but i still got upset over it and my dad said if you feel like crying over that i need to know about it i was angry because of it my parents didn't like it and my mom was in the wrong i remember her asking my brother about it but he wasn't paying attention my sister had told her and i about how my mom was doing and that we could be her friends but it wasn't enough so we left i told my parents to get some things together and i asked her to stay i was scared my mom said yes she didn't know what to say my brother was terrified of this woman he was never happy with her i would hear them fighting over him but it wasn't real i think he had no idea about her until i mentioned her and i got him a letter saying that i didn't care i asked him to do it but he didn't and he left we did it all the time together but i was a mess in college and the kids would be in my class the teachers didn't care and it was the same school so the students could play it cool i don't remember how the kids were dressed but i do recall my name being mentioned and that my mom was wearing a hat i was told my mother had her hair down i remember thinking that it looked good but my dad did not approve so i kept it but the kids at school knew the difference and my parents were angry i told them that the next day i would tell them but not before the funeral i got up at and left they had no idea i had died because they didn't know the story of my death the cops and the funeral director told me i was fine but that my father had died that morning i didn't understand that at all it was my dad i cried for days but he would be okay my mom told me i was crazy because of this and then my sister got married and the whole family was gone she said that the next day and her wedding dress was at the mall so they could buy it from her they didn't have her purse but i was sure there was a credit card she would use i also knew that they had her laptop i then tried to talk to the girl again the conversation ended when i asked her about her dad i think she just got angry i don't know but she didn't have the answer i was shocked when my dad said you can see the light i think he's telling the truth i am very scared but i guess it can happen i will stay awake the whole time and the other guys will sleep around the house in the basement my wife has been getting her period and we don't need to worry about\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "predictions = np.load('../../results/S1/perceived_speech/wheretheressmoke_BASE_MLP.npz', allow_pickle=True)\n",
    "print(' '.join(predictions['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = load_textgrids(stories, config.DATA_TRAIN_DIR)\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"respdict.json\"), \"r\") as f:\n",
    "    respdict = json.load(f)\n",
    "trfiles = load_simulated_trfiles(respdict)\n",
    "wordseqs = make_word_ds(grids, trfiles)\n",
    "return wordseqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "base = np.load('../scores/S1/perceived_speech/wheretheressmoke.npz', allow_pickle=True)\n",
    "mlp = np.load('../scores/S1/perceived_speech/wheretheressmoke_mlp.npz', allow_pickle=True)\n",
    "gpt2 = np.load('../scores/S1/perceived_speech/wheretheressmoke_gpt2.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('wheretheressmoke', 'WER'): 12.656749219799638, ('wheretheressmoke', 'BLEU'): 5.750169501152248, ('wheretheressmoke', 'METEOR'): 6.447097391696413, ('wheretheressmoke', 'BERT'): 12.795977}\n",
      "{('wheretheressmoke', 'WER'): 1.9219846660381588, ('wheretheressmoke', 'BLEU'): -0.5513700296316832, ('wheretheressmoke', 'METEOR'): 1.2374410749343323, ('wheretheressmoke', 'BERT'): 2.7528594}\n",
      "{('wheretheressmoke', 'WER'): -13.071730618874115, ('wheretheressmoke', 'BLEU'): -22.25487294995505, ('wheretheressmoke', 'METEOR'): -16.06553233150744, ('wheretheressmoke', 'BERT'): -33.929707}\n"
     ]
    }
   ],
   "source": [
    "print(base['story_zscores'])\n",
    "print(mlp['story_zscores'])\n",
    "print(gpt2['story_zscores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.close()\n",
    "mlp.close()\n",
    "gpt2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the contents of the NPZ file\n",
    "# The contents are stored as a dictionary-like object\n",
    "# You can access each array using its key\n",
    "array1 = data['array1_key']\n",
    "array2 = data['array2_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the NPZ file after use\n",
    "data.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
